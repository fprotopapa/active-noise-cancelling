{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering and Restoring of Mixed and Noise Polluted Audio Samples Using Different Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Edited Audio Samples and Generate Mixed Signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "inp_folder = 'unedited_samples'\n",
    "outp_folder = 'audio_samples'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = ['speech.wav', 'street-noise.wav', 'music.wav', 'white-noise.wav', 'tone_10kHz.wav']\n",
    "\n",
    "audio_speech, sr_speech = sf.read(os.path.join(inp_folder, file_names[0]))\n",
    "audio_street, sr_street = sf.read(os.path.join(inp_folder, file_names[1]))\n",
    "audio_music, sr_music = sf.read(os.path.join(inp_folder, file_names[2]))\n",
    "audio_wnoise, sr_wnoise = sf.read(os.path.join(inp_folder, file_names[3]))\n",
    "audio_test_tone, sr_test_tone = sf.read(os.path.join(inp_folder, file_names[4]))\n",
    "print(\"Array Type is: {}\".format(audio_music.dtype))\n",
    "# Attenuate white noise \n",
    "attenuation_ratio = 1/4\n",
    "audio_files = [audio_speech, audio_street, audio_music, audio_wnoise * attenuation_ratio, audio_test_tone]\n",
    "sample_rates = [sr_speech, sr_street, sr_music, sr_wnoise, sr_test_tone]\n",
    "\n",
    "for name, sr, audio in zip(file_names, sample_rates, audio_files):\n",
    "    print(\"File: {}, Sample Rate: {}, Samples: {}, Time: {}sec\".format(name, sr, len(audio), len(audio)/sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_mono = True\n",
    "# Reduce from stereo to mono\n",
    "if make_mono:\n",
    "    for ii, audio in enumerate(audio_files):\n",
    "        if len(audio.shape) == 2:\n",
    "            peak_l = max(audio[:, 0])\n",
    "            peak_r = max(audio[:, 1])\n",
    "            peak_pre = max(peak_l, peak_r)\n",
    "            audio_files[ii] = np.sum(audio, axis=1)\n",
    "            audio_files[ii] /= max(audio_files[ii])\n",
    "            audio_files[ii] *= peak_pre\n",
    "            print(\"Shape File {}: {}\".format(ii+1, audio_files[ii].shape))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import samplerate\n",
    "\n",
    "max_sr = max(sample_rates)\n",
    "converter = 'sinc_best'\n",
    "\n",
    "for ii, (audio, sr) in enumerate(zip(audio_files, sample_rates)):\n",
    "    if sr != max_sr:\n",
    "        ratio = max_sr / sr\n",
    "        audio_files[ii] = samplerate.resample(audio, ratio, converter)\n",
    "        print(\"New Shape: {}\".format(audio_files[ii].shape))\n",
    "        sample_rates[ii] = max_sr\n",
    "        \n",
    "for name, audio in zip(file_names, audio_files):\n",
    "    print(\"File: {}, Sample Rate: {}, Samples: {}, Time: {}sec\".format(name, max_sr, len(audio), len(audio)/sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find minimal audio length\n",
    "audio_length = []\n",
    "for ii, audio in enumerate(audio_files):\n",
    "    audio_length.append(len(audio))\n",
    "max_length = min(audio_length)\n",
    "print(\"Minimal number of audio samples: {}\".format(max_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine Audio length\n",
    "# Neede samples are samples = time * sample_rate\n",
    "time = max_length / sample_rates[audio_length.index(max_length)]\n",
    "\n",
    "adj_audio_length = []\n",
    "for sr in sample_rates:\n",
    "    adj_audio_length.append(int(time * sr))\n",
    "\n",
    "print(\"Max audio length is {} s\".format(time))\n",
    "for name, smp_has, smp_should in zip(file_names, audio_length, adj_audio_length):\n",
    "    print(\"File {} has {} Samples and must have {}\".format(name, smp_has, smp_should))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unify audio file length\n",
    "for ii, smp in enumerate(adj_audio_length):\n",
    "    audio_files[ii] = audio_files[ii][:smp]\n",
    "    print(\"Shape file {}: {}\".format(ii+1, audio_files[ii].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time-Domain\n",
    "\n",
    "Time plot of original audio files $u$ and noise sources $v$.\n",
    "\n",
    "| Audio | Symbol |\n",
    "| --- | --- |\n",
    "| Speech | $u_s$ | \n",
    "| Street Noise | $v_{sn}$ |\n",
    "| Music | $u_m$ |\n",
    "| White Noise | $v_{wn}$ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(len(audio_files), 1, figsize=[18, 10], sharex=False, constrained_layout = True)\n",
    "audio_names = ['Speech $u_s$', 'Street Noise $v_{sn}$', 'Music $u_m$', 'White Noise $v_{wn}$', 'Tone 10kHz']\n",
    "colors = ['blue', 'red', 'green', 'black', 'orange']\n",
    "for ii, (audio, name, sr, color) in enumerate(zip(audio_files, audio_names, sample_rates, colors)):\n",
    "    x_axis = np.arange(0, len(audio)) / sr\n",
    "    axs[ii].plot(x_axis, audio, lw=5, color=color)\n",
    "    axs[ii].set_title(name, fontsize=25)\n",
    "\n",
    "fig.supylabel('Amplitude', fontsize=20)\n",
    "fig.supxlabel('Time in Sec', fontsize=20)\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set_xlim(0)\n",
    "    ax.tick_params(labelsize=15)\n",
    "    ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectrum\n",
    "\n",
    "Frequencies in original audio files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fast Fourier Transform\n",
    "from scipy.fftpack import fft, fftfreq\n",
    "\n",
    "spectrums = []\n",
    "fft_x = []\n",
    "for audio, sample_rate, samples in zip(audio_files, sample_rates, adj_audio_length):\n",
    "    frequencies = fft(audio)\n",
    "    T = 1/sample_rate\n",
    "    x_axis = fftfreq(samples, T)[:samples//2]\n",
    "    spectrums.append(2.0/samples * np.abs(frequencies[0:samples//2]))\n",
    "    fft_x.append(x_axis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(len(audio_files), 1, figsize=[18, 10], sharex=False, constrained_layout = True)\n",
    "\n",
    "for ii, (spectrum, x_axis, name, color) in enumerate(zip(spectrums, fft_x, audio_names, colors)):\n",
    "    axs[ii].plot(x_axis / 1e3, spectrum, lw=5, color=color)\n",
    "    axs[ii].set_title(name, fontsize=25)\n",
    "\n",
    "fig.supylabel('Magnitude', fontsize=20)\n",
    "fig.supxlabel('Frequency in kHz', fontsize=20)\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set_xlim(0)\n",
    "    ax.tick_params(labelsize=15)\n",
    "    ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Files\n",
    "names_source_out = ['speech.wav', 'street.wav', 'music.wav', 'white_noise.wav', 'tone_10kHz.wav']\n",
    "for name, audio, sr in zip(names_source_out, audio_files, sample_rates):\n",
    "    sf.write(os.path.join(outp_folder, name), audio, sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mix Signals\n",
    "\n",
    "Generate four observations $d$. \n",
    "\n",
    "1. Music + White Noise $d_{m+wn}$\n",
    "1. Street Noise + Music $d_{sn+m}$\n",
    "1. Street Noise + Music + Speech $d_{sn+m+s}$\n",
    "1. Speech + White Noise $d_{s+wn}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1           Music +       White Noise\n",
    "d_m_wn = audio_files[2] + audio_files[3]\n",
    "# 2           Street +      Music\n",
    "d_sn_m = audio_files[1] + audio_files[2]\n",
    "# 3 :         Street +      Music +             Speech\n",
    "d_sn_m_s = audio_files[1] + audio_files[2] + audio_files[0]\n",
    "# 4 :         Speech +      White Noise\n",
    "d_s_wn = audio_files[0] + audio_files[3]\n",
    "\n",
    "observations = [d_m_wn, d_sn_m, d_sn_m_s, d_s_wn]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Files\n",
    "outp_folder = 'mixed_signals'\n",
    "names_out = ['music_wn.wav', 'street_music.wav', 'street_music_speech.wav', 'speech_wn.wav']\n",
    "for name, audio, sr in zip(names_out, observations, sample_rates):\n",
    "    sf.write(os.path.join(outp_folder, name), audio, sr)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8f290e9bb47e8cefb2a6a7867fb7ca058fb5b0f6b464d9af75d9c3f02494833d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('anc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
