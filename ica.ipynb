{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering and Restoring of Mixed and Noise Polluted Audio Samples Using Different Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Independent Component Analysis (ICA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Edited Audio Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "\n",
    "inp_folder = 'audio_samples'\n",
    "outp_folder = 'mixed_signals'\n",
    "ica_folder = 'ica_samples'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = ['speech.wav', 'street.wav', 'music.wav', 'white_noise.wav']\n",
    "\n",
    "audio_speech, sr_speech = sf.read(os.path.join(inp_folder, file_names[0]))\n",
    "audio_street, sr_street = sf.read(os.path.join(inp_folder, file_names[1]))\n",
    "audio_music, sr_music = sf.read(os.path.join(inp_folder, file_names[2]))\n",
    "audio_wnoise, sr_wnoise = sf.read(os.path.join(inp_folder, file_names[3]))\n",
    "\n",
    "print(\"Array Type is: {}\".format(audio_music.dtype))\n",
    "\n",
    "audio_files = [audio_speech, audio_street, audio_music, audio_wnoise]\n",
    "sample_rates = [sr_speech, sr_street, sr_music, sr_wnoise]\n",
    "max_length = len(audio_files[0])\n",
    "\n",
    "for name, sr, audio in zip(file_names, sample_rates, audio_files):\n",
    "    print(\"File: {}, Sample Rate: {}, Samples: {}, Time: {}sec\".format(name, sr, len(audio), len(audio)/sr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ICA\n",
    "\n",
    "ICA is a method for seperating a multivariate signal into components. \n",
    "\n",
    "Steps:\n",
    "\n",
    "1. Center $\\mathbf{d}$ by subtracting the mean\n",
    "1. Whiten\n",
    "1. Choose random initial value for the de-mixing matrix $\\mathbf{W}$\n",
    "1. Calculate the new value for $\\mathbf{W}$\n",
    "1. Normalize $\\mathbf{W}$\n",
    "1. Check whether algorithm has converged and if it hasnâ€™t, return to step 4\n",
    "1. Take the dot product of $\\mathbf{W}$ and $\\mathbf{d}$ to get the independent source signals\n",
    "$$\\mathbf{S} = \\mathbf{W}\\mathbf{d}$$\n",
    "\n",
    "Source:\n",
    "* [Independent Component Analysis (ICA) In Python, Cory Maklin](https://towardsdatascience.com/independent-component-analysis-ica-in-python-a0ef0db0955e)\n",
    "* [Separating mixed signals with Independent Component Analysis, Carsten Klein](https://towardsdatascience.com/separating-mixed-signals-with-independent-component-analysis-38205188f2f4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import FastICA\n",
    "\n",
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Observation using True Signals\n",
    "\n",
    "Generating signals for observation #3 and apply to \"cocktail party problem\". \n",
    "\n",
    "One recording per existing signal is used here. The recorded signal contains a proportion of pollution caused by the other signals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Street Noise + Music + Speech $d_{sn+m+s}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 :                   Street +            Music +                 Speech\n",
    "d_sn_m_s_1 = 0.3 * audio_files[1] + 0.3 * audio_files[2] + 0.4 * audio_files[0]\n",
    "d_sn_m_s_2 = 0.6 * audio_files[1] + 0.2 * audio_files[2] + 0.2 * audio_files[0]\n",
    "d_sn_m_s_3 = 0.1 * audio_files[1] + 0.7 * audio_files[2] + 0.2 * audio_files[0]\n",
    "true_signal = np.c_[audio_files[0], audio_files[1], audio_files[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 1, figsize=[30, 20], sharex=True, constrained_layout = True)\n",
    "fig.supylabel('Amplitude', fontsize=20)\n",
    "fig.supxlabel('Samples', fontsize=20)\n",
    "fig.suptitle('Street Noise + Music + Speech $d_{sn+m+s}$', fontsize=25)\n",
    "\n",
    "axs[0].plot(d_sn_m_s_1, lw=5, color='blue')\n",
    "axs[0].set_title('Signal 1', fontsize=25)\n",
    "axs[1].plot(d_sn_m_s_2, lw=5, color='red')\n",
    "axs[1].set_title('Signal 2', fontsize=25)\n",
    "axs[2].plot(d_sn_m_s_3, lw=5, color='black')\n",
    "axs[2].set_title('Signal 3', fontsize=25)\n",
    "\n",
    "for ax in axs: \n",
    "    ax.set_xlim(0, max_length)\n",
    "    ax.tick_params(labelsize=15)\n",
    "    ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine and Normalize Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation = np.c_[d_sn_m_s_1, d_sn_m_s_2, d_sn_m_s_3]\n",
    "\n",
    "observation /= observation.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Additional Distortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_distortion = False\n",
    "if add_distortion:\n",
    "    mixing = np.array([[0.5, 1, 0.2],\n",
    "                        [1, 0.5, 0.4],\n",
    "                        [0.5, 0.8, 1]])\n",
    "                        \n",
    "    observation = np.dot(true_signal, mixing.T) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save ICA signal\n",
    "def save_ica_audio(audio, name, folder):\n",
    "    names_ica = []\n",
    "    for ii in range(audio.shape[1]):\n",
    "        names_ica.append('ica_{}_ch{}.wav'.format(name, ii+1))\n",
    "\n",
    "    for ii, (name, sr) in enumerate(zip(names_ica, sample_rates)):\n",
    "        sf.write(os.path.join(folder, name), audio[:,ii], sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply FastICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica = FastICA()\n",
    "ica_recovered = ica.fit_transform(observation) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_plot = False\n",
    "if simple_plot:\n",
    "    fig, axs = plt.subplots(3, 1, figsize=[30, 20], sharex=True, constrained_layout = True)\n",
    "    fig.supylabel('Amplitude', fontsize=20)\n",
    "    fig.supxlabel('Samples', fontsize=20)\n",
    "    fig.suptitle('Street Noise + Music + Speech $d_{sn+m+s}$', fontsize=25)\n",
    "    \n",
    "    axs[0].plot(ica_recovered[:, 0], lw=5, color='blue')\n",
    "    axs[0].set_title('ICA Recovered', fontsize=25)\n",
    "    axs[1].plot(ica_recovered[:, 1], lw=5, color='red')\n",
    "    axs[2].plot(ica_recovered[:, 2], lw=5, color='black')\n",
    "\n",
    "    for ax in axs: \n",
    "        ax.set_xlim(0, max_length)\n",
    "        ax.tick_params(labelsize=15)\n",
    "        ax.grid()\n",
    "else:\n",
    "    ica_lst = [observation, true_signal, ica_recovered]\n",
    "    ica_name = ['Observation', 'True Signal', 'ICA Recovered']\n",
    "    fig, axs = plt.subplots(3, 3, figsize=[30, 20], sharex=True, constrained_layout = True)\n",
    "    fig.supylabel('Amplitude', fontsize=20)\n",
    "    fig.supxlabel('Samples', fontsize=20)\n",
    "    fig.suptitle('Street Noise + Music + Speech $d_{sn+m+s}$', fontsize=25)\n",
    "\n",
    "    for ii, (data, name) in enumerate(zip(ica_lst, ica_name)):\n",
    "        axs[0][ii].plot(data[:, 0], lw=5, color='blue')\n",
    "        axs[0][ii].set_title(name, fontsize=25)\n",
    "        axs[1][ii].plot(data[:, 1], lw=5, color='red')\n",
    "        axs[2][ii].plot(data[:, 2], lw=5, color='black')\n",
    "\n",
    "    for row in axs: \n",
    "        for ax in row: \n",
    "            ax.set_xlim(0, max_length)\n",
    "            ax.tick_params(labelsize=15)\n",
    "            ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save observations and recovered signal\n",
    "save_ica_audio(ica_recovered, 'recv_sig3', ica_folder)\n",
    "save_ica_audio(observation, 'obsv_sig3', outp_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform ICA for the remaining test observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ica(true_sig, observation, signal_name, add_distort=False):\n",
    "    true_sig /= true_sig.std(axis=0)\n",
    "    observation /= observation.std(axis=0)\n",
    "\n",
    "    if add_distort:\n",
    "        mixing = np.array([[0.5, 1],\n",
    "                            [0.8, 0.2]])\n",
    "        observation = np.dot(true_sig, mixing.T)\n",
    "        \n",
    "    ica = FastICA()\n",
    "    ica_recovered = ica.fit_transform(observation)\n",
    "\n",
    "    ica_lst = [observation, true_sig, ica_recovered]\n",
    "    ica_name = ['Observation', 'True Signal', 'ICA Recovered']\n",
    "    fig, axs = plt.subplots(2, 3, figsize=[30, 20], sharex=True, constrained_layout = True)\n",
    "    fig.supylabel('Amplitude', fontsize=20)\n",
    "    fig.supxlabel('Samples', fontsize=20)\n",
    "\n",
    "    save_ica_audio(ica_recovered, 'recv_{}'.format(signal_name), ica_folder)\n",
    "    save_ica_audio(observation, 'obsv_{}'.format(signal_name), outp_folder)\n",
    "\n",
    "    equalize_amp = False\n",
    "    if equalize_amp:\n",
    "        ratio = np.abs(true_sig).mean() / np.abs(ica_recovered).mean()\n",
    "        for ii in range(ica_recovered.shape[1]):\n",
    "            ica_recovered[:, ii] = ica_recovered[:, ii] * ratio\n",
    "    \n",
    "    for ii, (data, name) in enumerate(zip(ica_lst, ica_name)):\n",
    "        axs[0][ii].plot(data[:, 0], lw=5, color='blue')\n",
    "        axs[0][ii].set_title(name, fontsize=25)\n",
    "        axs[1][ii].plot(data[:, 1], lw=5, color='red')\n",
    "\n",
    "    for row in axs: \n",
    "        for ax in row: \n",
    "            ax.set_xlim(0, max_length)\n",
    "            ax.tick_params(labelsize=15)\n",
    "            ax.grid()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remaining Signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1                 Music +             White Noise\n",
    "d_m_wn_1 = 0.7 * audio_files[2] + 0.3 * audio_files[3]\n",
    "d_m_wn_2 = 0.3 * audio_files[2] + 0.7 * audio_files[3]\n",
    "observation_1 = np.c_[d_m_wn_1, d_m_wn_2]\n",
    "true_signal_1 = np.c_[audio_files[2], audio_files[3]]\n",
    "# 2                 Street +            Music\n",
    "d_sn_m_1 = 0.7 * audio_files[1] + 0.3 * audio_files[2]\n",
    "d_sn_m_2 = 0.3 * audio_files[1] + 0.7 * audio_files[2]\n",
    "observation_2 = np.c_[d_sn_m_1, d_sn_m_2]\n",
    "true_signal_2 = np.c_[audio_files[1], audio_files[2]]\n",
    "# 4 :               Speech +            White Noise\n",
    "d_s_wn_1 = 0.7 * audio_files[0] + 0.3 * audio_files[3]\n",
    "d_s_wn_2 = 0.3 * audio_files[0] + 0.7 * audio_files[3]\n",
    "observation_4 = np.c_[d_s_wn_1, d_s_wn_2]\n",
    "true_signal_4 = np.c_[audio_files[0], audio_files[3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music + White Noise $d_{m+wn}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica(true_signal_1, observation_1, 'sig1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Street Noise + Music $d_{sn+m}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica(true_signal_2, observation_2, 'sig2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech + White Noise $d_{s+wn}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica(true_signal_4, observation_4, 'sig4')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8f290e9bb47e8cefb2a6a7867fb7ca058fb5b0f6b464d9af75d9c3f02494833d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('anc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
